{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Bu not defterinde şuana kadar yaptığımız herşeyi bir sınıf yapısı altında birleştirerek\n",
    "bir katman oluşturacağız. Nöral ağlar birbirinden farklı katmanların bir araya gelmesi\n",
    "ile oluşur. Örneğin evrişimsen sinir ağlarında, dense, maxpooling gibi farklı görevleri\n",
    "olan katmnalar bulunur. Bu katmanları arka arkaya dizerek bir nöral ağ oluştururuz.\n",
    "\n",
    "En temel nöral ağ yapısı aşağıdaki gibisir. Her nöral ağda girdiyi şekillendiren bir **Input\n",
    "Layer** bir de sonucun gözlemleneceği **Output Layer** bulunur. Bu iki katman arasında bulunan\n",
    "diğer katmanların hepsi **Hidden Layer** olarak adlandırlır. Hidden Layer'ların sayılar ve tipleri\n",
    "kullanıcı tarafından belirlenir.\n",
    "\n",
    "![](https://machinelearningmastery.com/wp-content/uploads/2021/08/neural_networks_21.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def prepare_the_image(imgPath):\n",
    "    img = cv.imread(imgPath, cv.IMREAD_GRAYSCALE)\n",
    "    img = img/255\n",
    "    flatten = img.flatten()\n",
    "    return flatten\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "flattenV = prepare_the_image(\"../dataset/train/vertical.png\")\n",
    "flattenH = prepare_the_image(\"../dataset/train/horizontal.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dataset = np.array([flattenV, flattenH])\n",
    "labels = np.array([[0, 1]]).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Katman sınıfımızı oluşturmaya başlayalım. Biz en temel katman yapısını oluşturacağız bu\n",
    "yüzden katmanımızın sadece iki işlevi olacak. Bunlar forward and back propagation işlemleri\n",
    "olacaktır. Eğer sınıf oluşturmaya hakim iseniz geçtiğimiz not defterinde kullandığımız\n",
    "fonksiyonları sınıfımızın içerisine entegre etmekten fazlasını yapmadığımı görebilirsiniz.\n",
    "\n",
    "Farklı olarak sınıf çağırıldığında çalışacak bir consturcter merhodu tanımladım. Bu methodun\n",
    "amacı katmana girecek matrisin boyutlarına bilmek istemem çünkü  işlemlerimi girdi boyutna\n",
    "göre yapamam gerekli."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(input_size, output_size)\n",
    "        print(\"Starting weights are . . .\")\n",
    "        print(self.weights)\n",
    "\n",
    "    def feed_forward(self, input):\n",
    "        weighted_sum = np.dot(input, self.weights)\n",
    "        output = sigmoid(weighted_sum)\n",
    "        return output\n",
    "\n",
    "    def back_propagation(self, input, output, labels):\n",
    "        error = output - labels\n",
    "        adjustment = error * sigmoid_der(output)\n",
    "        weights_update = np.dot(input.T, adjustment)\n",
    "        self.weights -= weights_update"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hemen aşağıda katmanımızı çağğıralım. 3x3 bir resimi düzleştridiğimiz de 9X1 bir matris elde\n",
    "ederiz, bu şekilde katmanıma matris boyutumu belirtitiyorum. Sonrasında 10 tur boyunca katmanın\n",
    "forward ve back propagation methodlarını çağırıyorum yani nöral ağımı eğitiyorum. En son\n",
    "elde ettiğim sonuçları çıktı olarak gözlemleyebilirsiniz."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights are . . .\n",
      "[[0.53173132]\n",
      " [0.35509124]\n",
      " [0.35441351]\n",
      " [0.7142355 ]\n",
      " [0.15548032]\n",
      " [0.02430959]\n",
      " [0.16116283]\n",
      " [0.39326071]\n",
      " [0.66534123]]\n"
     ]
    }
   ],
   "source": [
    "layer1 = Layer(9, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    output = layer1.feed_forward(dataset)\n",
    "    layer1.back_propagation(dataset, output, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dataset :: \n",
      " [[0. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 0. 0.]]\n",
      "Labels are :: \n",
      " [[0]\n",
      " [1]]\n",
      "Final weights are . . . \n",
      " [[ 0.53173132]\n",
      " [-0.59899535]\n",
      " [ 0.35441351]\n",
      " [ 1.2419897 ]\n",
      " [-0.27085207]\n",
      " [ 0.55206379]\n",
      " [ 0.16116283]\n",
      " [-0.56082589]\n",
      " [ 0.66534123]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input dataset :: \\n\", dataset)\n",
    "print(\"Labels are :: \\n\", labels)\n",
    "print(\"Final weights are . . . \\n\", layer1.weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}